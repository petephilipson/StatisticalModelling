<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 Categorical variables and interactions | notes</title>
  <meta name="description" content="" />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="4 Categorical variables and interactions | notes" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Categorical variables and interactions | notes" />
  
  
  

<meta name="author" content="Dr Pete Philipson" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="inference-for-the-multiple-linear-regression-model.html"/>
<link rel="next" href="analysis-of-designed-experiments.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>MAS3928: Statistical Modelling</a></li>
<li class="chapter" data-level="" data-path="module-information.html"><a href="module-information.html"><i class="fa fa-check"></i>Module information</a>
<ul>
<li class="chapter" data-level="" data-path="module-information.html"><a href="module-information.html#lecturer-information"><i class="fa fa-check"></i>Lecturer information</a></li>
<li class="chapter" data-level="" data-path="module-information.html"><a href="module-information.html#module-schedule"><i class="fa fa-check"></i>Module schedule</a></li>
<li class="chapter" data-level="" data-path="module-information.html"><a href="module-information.html#course-materials"><i class="fa fa-check"></i>Course materials</a></li>
<li class="chapter" data-level="" data-path="module-information.html"><a href="module-information.html#assessment"><i class="fa fa-check"></i>Assessment</a></li>
<li class="chapter" data-level="" data-path="module-information.html"><a href="module-information.html#relevant-texts"><i class="fa fa-check"></i>Relevant texts</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#multiple-linear-regression"><i class="fa fa-check"></i><b>1.1</b> Multiple linear regression</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#matrix-form-of-the-model"><i class="fa fa-check"></i><b>1.2</b> Matrix form of the model</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#example---matrix-form-for-pre-diabetes-data"><i class="fa fa-check"></i>Example - Matrix form for pre-diabetes data</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#parameter-estimation"><i class="fa fa-check"></i><b>1.3</b> Parameter estimation</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="introduction.html"><a href="introduction.html#estimation-of-underlinebeta"><i class="fa fa-check"></i><b>1.3.1</b> Estimation of <span class="math inline">\(\underline{\beta}\)</span></a></li>
<li class="chapter" data-level="1.3.2" data-path="introduction.html"><a href="introduction.html#estimation-of-sigma_epsilon2"><i class="fa fa-check"></i><b>1.3.2</b> Estimation of <span class="math inline">\(\sigma_{\epsilon}^2\)</span></a></li>
<li class="chapter" data-level="1.3.3" data-path="introduction.html"><a href="introduction.html#sec:resfithat"><i class="fa fa-check"></i><b>1.3.3</b> Residuals, fitted values and the ‘hat matrix’</a></li>
<li class="chapter" data-level="1.3.4" data-path="introduction.html"><a href="introduction.html#properties-of-the-hat-matrix"><i class="fa fa-check"></i><b>1.3.4</b> Properties of the hat matrix</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#example-multiple-linear-regresion-analysis-of-bodyweight-data"><i class="fa fa-check"></i>Example: Multiple linear regresion analysis of bodyweight data</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#expectations-variances-and-inference"><i class="fa fa-check"></i><b>1.4</b> Expectations, variances and inference</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="introduction.html"><a href="introduction.html#expectation-of-underlinehatbeta"><i class="fa fa-check"></i><b>1.4.1</b> Expectation of <span class="math inline">\(\underline{\hat{\beta}}\)</span></a></li>
<li class="chapter" data-level="1.4.2" data-path="introduction.html"><a href="introduction.html#variance-of-underlinehatbeta"><i class="fa fa-check"></i><b>1.4.2</b> Variance of <span class="math inline">\(\underline{\hat{\beta}}\)</span></a></li>
<li class="chapter" data-level="1.4.3" data-path="introduction.html"><a href="introduction.html#sec:inferforbetahat"><i class="fa fa-check"></i><b>1.4.3</b> Inference for <span class="math inline">\(\underline{\hat{\beta}}\)</span></a></li>
<li class="chapter" data-level="1.4.4" data-path="introduction.html"><a href="introduction.html#sec:expvaryhat"><i class="fa fa-check"></i><b>1.4.4</b> Expectation and variance of the fitted values</a></li>
<li class="chapter" data-level="1.4.5" data-path="introduction.html"><a href="introduction.html#expectation-and-variance-of-the-residuals"><i class="fa fa-check"></i><b>1.4.5</b> Expectation and variance of the residuals</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#sec:mlrinr"><i class="fa fa-check"></i><b>1.5</b> Multiple linear regression in <code>R</code></a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="introduction.html"><a href="introduction.html#using-data-in-r"><i class="fa fa-check"></i><b>1.5.1</b> Using data in <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#example-analysis-of-bodyweight-data-using-r"><i class="fa fa-check"></i>Example: Analysis of bodyweight data using <code>R</code></a></li>
<li class="chapter" data-level="1.6" data-path="introduction.html"><a href="introduction.html#the-role-of-the-intercept"><i class="fa fa-check"></i><b>1.6</b> The role of the intercept</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#example-analysis-of-bodyweight-data-without-an-intercept-term"><i class="fa fa-check"></i>Example: Analysis of bodyweight data without an intercept term</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#example-analysis-of-mens-premier-league-football-data---the-role-of-the-intercept"><i class="fa fa-check"></i>Example: Analysis of men’s Premier League football data - the role of the intercept</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="introduction.html"><a href="introduction.html#interpretability-of-the-intercept-and-extrapolation"><i class="fa fa-check"></i><b>1.6.1</b> Interpretability of the intercept and extrapolation</a></li>
<li class="chapter" data-level="1.6.2" data-path="introduction.html"><a href="introduction.html#mean-centering-of-covariates"><i class="fa fa-check"></i><b>1.6.2</b> Mean-centering of covariates</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#example-mean-centering-mens-premier-league-football-data"><i class="fa fa-check"></i>Example: Mean-centering (men’s Premier League football data)</a></li>
<li class="chapter" data-level="1.7" data-path="introduction.html"><a href="introduction.html#sec:multicol"><i class="fa fa-check"></i><b>1.7</b> Properties of <span class="math inline">\(\left(\mathrm{X}^T\mathrm{X}\right)^{-1}\)</span>: multicollinearity</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#example-multicollinearity-in-mens-premier-league-football-data"><i class="fa fa-check"></i>Example: Multicollinearity in men’s Premier League football data</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="regression-diagnostics.html"><a href="regression-diagnostics.html"><i class="fa fa-check"></i><b>2</b> Regression diagnostics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="regression-diagnostics.html"><a href="regression-diagnostics.html#standardised-residuals"><i class="fa fa-check"></i><b>2.1</b> Standardised residuals</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="regression-diagnostics.html"><a href="regression-diagnostics.html#residual-plots"><i class="fa fa-check"></i><b>2.1.1</b> Residual plots</a></li>
<li class="chapter" data-level="" data-path="regression-diagnostics.html"><a href="regression-diagnostics.html#correlation-between-residuals-and-fitted-values"><i class="fa fa-check"></i>Correlation between residuals and fitted values</a></li>
<li class="chapter" data-level="2.1.2" data-path="regression-diagnostics.html"><a href="regression-diagnostics.html#outliers"><i class="fa fa-check"></i><b>2.1.2</b> Outliers</a></li>
<li class="chapter" data-level="" data-path="regression-diagnostics.html"><a href="regression-diagnostics.html#example-residual-analysis-for-pre-diabetes-data"><i class="fa fa-check"></i>Example: Residual analysis for pre-diabetes data</a></li>
<li class="chapter" data-level="2.1.3" data-path="regression-diagnostics.html"><a href="regression-diagnostics.html#normality-of-the-residuals"><i class="fa fa-check"></i><b>2.1.3</b> Normality of the residuals</a></li>
<li class="chapter" data-level="2.1.4" data-path="regression-diagnostics.html"><a href="regression-diagnostics.html#anderson-darling-test"><i class="fa fa-check"></i><b>2.1.4</b> Anderson-Darling test</a></li>
<li class="chapter" data-level="" data-path="regression-diagnostics.html"><a href="regression-diagnostics.html#a-cautionary-note"><i class="fa fa-check"></i>A cautionary note</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="regression-diagnostics.html"><a href="regression-diagnostics.html#regression-diagnostics-1"><i class="fa fa-check"></i><b>2.2</b> Regression diagnostics</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="regression-diagnostics.html"><a href="regression-diagnostics.html#leverage-values"><i class="fa fa-check"></i><b>2.2.1</b> Leverage values</a></li>
<li class="chapter" data-level="" data-path="regression-diagnostics.html"><a href="regression-diagnostics.html#example-leverage-values-for-the-pre-diabetes-data"><i class="fa fa-check"></i>Example: Leverage values for the pre-diabetes data</a></li>
<li class="chapter" data-level="2.2.2" data-path="regression-diagnostics.html"><a href="regression-diagnostics.html#influential-observations"><i class="fa fa-check"></i><b>2.2.2</b> Influential observations</a></li>
<li class="chapter" data-level="2.2.3" data-path="regression-diagnostics.html"><a href="regression-diagnostics.html#dealing-with-unusual-observations"><i class="fa fa-check"></i><b>2.2.3</b> Dealing with unusual observations</a></li>
<li class="chapter" data-level="" data-path="regression-diagnostics.html"><a href="regression-diagnostics.html#example-model-checking-for-the-premier-league-data"><i class="fa fa-check"></i>Example: Model checking for the Premier League data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="inference-for-the-multiple-linear-regression-model.html"><a href="inference-for-the-multiple-linear-regression-model.html"><i class="fa fa-check"></i><b>3</b> Inference for the multiple linear regression model</a>
<ul>
<li class="chapter" data-level="3.1" data-path="inference-for-the-multiple-linear-regression-model.html"><a href="inference-for-the-multiple-linear-regression-model.html#assessing-the-fit"><i class="fa fa-check"></i><b>3.1</b> Assessing the fit</a></li>
<li class="chapter" data-level="3.2" data-path="inference-for-the-multiple-linear-regression-model.html"><a href="inference-for-the-multiple-linear-regression-model.html#the-basic-anova-table"><i class="fa fa-check"></i><b>3.2</b> The basic anova table</a>
<ul>
<li class="chapter" data-level="" data-path="inference-for-the-multiple-linear-regression-model.html"><a href="inference-for-the-multiple-linear-regression-model.html#cochrans-theorem"><i class="fa fa-check"></i>Cochran’s Theorem</a></li>
<li class="chapter" data-level="" data-path="inference-for-the-multiple-linear-regression-model.html"><a href="inference-for-the-multiple-linear-regression-model.html#the-coefficient-of-determination"><i class="fa fa-check"></i>The coefficient of determination</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="inference-for-the-multiple-linear-regression-model.html"><a href="inference-for-the-multiple-linear-regression-model.html#example-cheddar-cheese-study"><i class="fa fa-check"></i>Example: Cheddar cheese study</a>
<ul>
<li class="chapter" data-level="" data-path="inference-for-the-multiple-linear-regression-model.html"><a href="inference-for-the-multiple-linear-regression-model.html#solution"><i class="fa fa-check"></i>Solution</a></li>
<li class="chapter" data-level="" data-path="inference-for-the-multiple-linear-regression-model.html"><a href="inference-for-the-multiple-linear-regression-model.html#anova-in-r"><i class="fa fa-check"></i>Anova in <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="inference-for-the-multiple-linear-regression-model.html"><a href="inference-for-the-multiple-linear-regression-model.html#the-extra-sum-of-squares-method"><i class="fa fa-check"></i><b>3.3</b> The extra sum of squares method</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="inference-for-the-multiple-linear-regression-model.html"><a href="inference-for-the-multiple-linear-regression-model.html#the-extended-anova-table"><i class="fa fa-check"></i><b>3.3.1</b> The extended anova table</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="inference-for-the-multiple-linear-regression-model.html"><a href="inference-for-the-multiple-linear-regression-model.html#example-extra-sum-of-squares-for-cheese-data"><i class="fa fa-check"></i>Example: Extra sum of squares for cheese data</a></li>
<li class="chapter" data-level="" data-path="inference-for-the-multiple-linear-regression-model.html"><a href="inference-for-the-multiple-linear-regression-model.html#example-warfarin-study"><i class="fa fa-check"></i>Example: Warfarin study</a></li>
<li class="chapter" data-level="3.4" data-path="inference-for-the-multiple-linear-regression-model.html"><a href="inference-for-the-multiple-linear-regression-model.html#the-general-extra-sum-of-squares-method"><i class="fa fa-check"></i><b>3.4</b> The general extra sum of squares method</a></li>
<li class="chapter" data-level="" data-path="inference-for-the-multiple-linear-regression-model.html"><a href="inference-for-the-multiple-linear-regression-model.html#example-extended-extra-sum-of-squares-for-cheese-data"><i class="fa fa-check"></i>Example: Extended extra sum of squares for cheese data</a>
<ul>
<li class="chapter" data-level="" data-path="inference-for-the-multiple-linear-regression-model.html"><a href="inference-for-the-multiple-linear-regression-model.html#summary-extra-sum-of-squares-method"><i class="fa fa-check"></i>Summary: extra sum of squares method</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="inference-for-the-multiple-linear-regression-model.html"><a href="inference-for-the-multiple-linear-regression-model.html#example-anova-for-crime-data-based-on-summary-information"><i class="fa fa-check"></i>Example: Anova for crime data based on summary information</a></li>
<li class="chapter" data-level="" data-path="inference-for-the-multiple-linear-regression-model.html"><a href="inference-for-the-multiple-linear-regression-model.html#solution-1"><i class="fa fa-check"></i>Solution</a></li>
<li class="chapter" data-level="3.5" data-path="inference-for-the-multiple-linear-regression-model.html"><a href="inference-for-the-multiple-linear-regression-model.html#confidence-and-prediction-intervals-for-the-fitted-values"><i class="fa fa-check"></i><b>3.5</b> Confidence and prediction intervals for the fitted values</a></li>
<li class="chapter" data-level="" data-path="inference-for-the-multiple-linear-regression-model.html"><a href="inference-for-the-multiple-linear-regression-model.html#example-confidence-and-prediction-intervals-for-the-cheese-data"><i class="fa fa-check"></i>Example: Confidence and prediction intervals for the cheese data</a></li>
<li class="chapter" data-level="3.6" data-path="inference-for-the-multiple-linear-regression-model.html"><a href="inference-for-the-multiple-linear-regression-model.html#sec:polymodels"><i class="fa fa-check"></i><b>3.6</b> Polynomial models</a></li>
<li class="chapter" data-level="" data-path="inference-for-the-multiple-linear-regression-model.html"><a href="inference-for-the-multiple-linear-regression-model.html#example-polynomial-model"><i class="fa fa-check"></i>Example: Polynomial model</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="inference-for-the-multiple-linear-regression-model.html"><a href="inference-for-the-multiple-linear-regression-model.html#choosing-the-order-of-a-polynomial-model"><i class="fa fa-check"></i><b>3.6.1</b> Choosing the order of a polynomial model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="categorical-variables-and-interactions.html"><a href="categorical-variables-and-interactions.html"><i class="fa fa-check"></i><b>4</b> Categorical variables and interactions</a>
<ul>
<li class="chapter" data-level="4.1" data-path="categorical-variables-and-interactions.html"><a href="categorical-variables-and-interactions.html#sec:indvars"><i class="fa fa-check"></i><b>4.1</b> Indicator and dummy variables</a></li>
<li class="chapter" data-level="" data-path="categorical-variables-and-interactions.html"><a href="categorical-variables-and-interactions.html#example-gasoline-data"><i class="fa fa-check"></i>Example: Gasoline data</a>
<ul>
<li class="chapter" data-level="" data-path="categorical-variables-and-interactions.html"><a href="categorical-variables-and-interactions.html#model-interpretation"><i class="fa fa-check"></i>Model interpretation</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="categorical-variables-and-interactions.html"><a href="categorical-variables-and-interactions.html#model-selection-criteria"><i class="fa fa-check"></i><b>4.2</b> Model selection criteria</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="categorical-variables-and-interactions.html"><a href="categorical-variables-and-interactions.html#model-selection-criteria-adjusted-r2"><i class="fa fa-check"></i><b>4.2.1</b> Model selection criteria: adjusted <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="4.2.2" data-path="categorical-variables-and-interactions.html"><a href="categorical-variables-and-interactions.html#model-selection-criteria-akaikes-information-criterion"><i class="fa fa-check"></i><b>4.2.2</b> Model selection criteria: Akaike’s Information Criterion</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="categorical-variables-and-interactions.html"><a href="categorical-variables-and-interactions.html#reducing-the-number-of-variables"><i class="fa fa-check"></i><b>4.3</b> Reducing the number of variables</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="categorical-variables-and-interactions.html"><a href="categorical-variables-and-interactions.html#backward-elimination"><i class="fa fa-check"></i><b>4.3.1</b> Backward elimination</a></li>
<li class="chapter" data-level="4.3.2" data-path="categorical-variables-and-interactions.html"><a href="categorical-variables-and-interactions.html#forward-selection"><i class="fa fa-check"></i><b>4.3.2</b> Forward selection</a></li>
<li class="chapter" data-level="4.3.3" data-path="categorical-variables-and-interactions.html"><a href="categorical-variables-and-interactions.html#stepwise-selection"><i class="fa fa-check"></i><b>4.3.3</b> Stepwise selection</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="categorical-variables-and-interactions.html"><a href="categorical-variables-and-interactions.html#multicollinearity-and-the-variance-inflation-factor"><i class="fa fa-check"></i><b>4.4</b> Multicollinearity and the variance inflation factor</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="categorical-variables-and-interactions.html"><a href="categorical-variables-and-interactions.html#variance-inflation-factors"><i class="fa fa-check"></i><b>4.4.1</b> Variance inflation factors</a></li>
<li class="chapter" data-level="" data-path="categorical-variables-and-interactions.html"><a href="categorical-variables-and-interactions.html#example-variance-inflation-factors"><i class="fa fa-check"></i>Example: Variance inflation factors</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="categorical-variables-and-interactions.html"><a href="categorical-variables-and-interactions.html#transformations"><i class="fa fa-check"></i><b>4.5</b> Transformations</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="categorical-variables-and-interactions.html"><a href="categorical-variables-and-interactions.html#the-box-cox-transformation"><i class="fa fa-check"></i><b>4.5.1</b> The Box-Cox transformation</a></li>
<li class="chapter" data-level="" data-path="categorical-variables-and-interactions.html"><a href="categorical-variables-and-interactions.html#example-box-cox-transformation"><i class="fa fa-check"></i>Example: Box-Cox transformation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="analysis-of-designed-experiments.html"><a href="analysis-of-designed-experiments.html"><i class="fa fa-check"></i><b>5</b> Analysis of designed experiments</a>
<ul>
<li class="chapter" data-level="5.1" data-path="analysis-of-designed-experiments.html"><a href="analysis-of-designed-experiments.html#completely-randomised-design"><i class="fa fa-check"></i><b>5.1</b> Completely randomised design</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="analysis-of-designed-experiments.html"><a href="analysis-of-designed-experiments.html#handling-factors-with-k-levels"><i class="fa fa-check"></i><b>5.1.1</b> Handling factors with <span class="math inline">\(k\)</span> levels</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="analysis-of-designed-experiments.html"><a href="analysis-of-designed-experiments.html#example-one-way-anova"><i class="fa fa-check"></i>Example: One-way anova</a>
<ul>
<li class="chapter" data-level="5.1.2" data-path="analysis-of-designed-experiments.html"><a href="analysis-of-designed-experiments.html#analysis-of-completely-randomised-design-data-in-r"><i class="fa fa-check"></i><b>5.1.2</b> Analysis of completely randomised design data in <code>R</code></a></li>
<li class="chapter" data-level="5.1.3" data-path="analysis-of-designed-experiments.html"><a href="analysis-of-designed-experiments.html#interpretation-of-results-multiple-comparisons"><i class="fa fa-check"></i><b>5.1.3</b> Interpretation of results: multiple comparisons</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="analysis-of-designed-experiments.html"><a href="analysis-of-designed-experiments.html#example-multiple-comparisons"><i class="fa fa-check"></i>Example: Multiple comparisons</a>
<ul>
<li class="chapter" data-level="5.1.4" data-path="analysis-of-designed-experiments.html"><a href="analysis-of-designed-experiments.html#model-checking"><i class="fa fa-check"></i><b>5.1.4</b> Model checking</a></li>
<li class="chapter" data-level="5.1.5" data-path="analysis-of-designed-experiments.html"><a href="analysis-of-designed-experiments.html#completely-randomised-design-dealing-with-quantitative-variables"><i class="fa fa-check"></i><b>5.1.5</b> Completely randomised design: dealing with quantitative variables</a></li>
<li class="chapter" data-level="" data-path="analysis-of-designed-experiments.html"><a href="analysis-of-designed-experiments.html#example-randomised-design-with-a-quantitative-variable"><i class="fa fa-check"></i>Example: Randomised design with a quantitative variable</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="analysis-of-designed-experiments.html"><a href="analysis-of-designed-experiments.html#randomised-block-design"><i class="fa fa-check"></i><b>5.2</b> Randomised block design</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="analysis-of-designed-experiments.html"><a href="analysis-of-designed-experiments.html#two-way-analysis-of-variance"><i class="fa fa-check"></i><b>5.2.1</b> Two-way analysis of variance</a></li>
<li class="chapter" data-level="5.2.2" data-path="analysis-of-designed-experiments.html"><a href="analysis-of-designed-experiments.html#orthogonality-and-testing-of-blocks-in-a-two-way-analysis-of-variance-model"><i class="fa fa-check"></i><b>5.2.2</b> Orthogonality and testing of blocks in a two-way analysis of variance model</a></li>
<li class="chapter" data-level="" data-path="analysis-of-designed-experiments.html"><a href="analysis-of-designed-experiments.html#example-two-way-anova-on-nitrate-data"><i class="fa fa-check"></i>Example: Two-way anova on nitrate data</a></li>
<li class="chapter" data-level="" data-path="analysis-of-designed-experiments.html"><a href="analysis-of-designed-experiments.html#example-chicken-egg-production"><i class="fa fa-check"></i>Example: Chicken egg production</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="analysis-of-designed-experiments.html"><a href="analysis-of-designed-experiments.html#factorial-experiments"><i class="fa fa-check"></i><b>5.3</b> Factorial experiments</a>
<ul>
<li class="chapter" data-level="" data-path="analysis-of-designed-experiments.html"><a href="analysis-of-designed-experiments.html#example-two-way-anova-with-interactions-for-the-yeast-data"><i class="fa fa-check"></i>Example: Two-way anova with interactions for the yeast data</a></li>
<li class="chapter" data-level="5.3.1" data-path="analysis-of-designed-experiments.html"><a href="analysis-of-designed-experiments.html#exploratory-plots-for-interactions"><i class="fa fa-check"></i><b>5.3.1</b> Exploratory plots for interactions</a></li>
<li class="chapter" data-level="" data-path="analysis-of-designed-experiments.html"><a href="analysis-of-designed-experiments.html#example-transforming-the-response"><i class="fa fa-check"></i>Example: Transforming the response</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="categorical-variables-and-interactions" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">4</span> Categorical variables and interactions<a href="categorical-variables-and-interactions.html#categorical-variables-and-interactions" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In the models considered thus far, we have had exclusively continuous covariates (multiple linear regression models). In reality, we are often faced with variables of other types within the same dataset, such as <em>categorical</em> covariates, e.g. smoking status or mode of transport. We will now consider a model with both types of covariate.</p>
<div id="sec:indvars" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Indicator and dummy variables<a href="categorical-variables-and-interactions.html#sec:indvars" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let us consider an example where there appeared to be a linear relationship between weight and length in both male and female lobsters. We may want to consider:</p>
<ol style="list-style-type: decimal">
<li>Is there a difference in the intercepts between males and females?</li>
<li>Is there a difference in the slopes?</li>
</ol>
<p>To handle a binary covariate, we can define an indicator variable which indicates the sex of the lobster. Let <span class="math inline">\(x_{i1} = 0\)</span> for a male and <span class="math inline">\(x_{i1} = 1\)</span> for a female, i.e.</p>
<p><span class="math display">\[
\color{red}{x_{i1} = \begin{cases} 1&amp; \text{if `Female`} \\
0&amp; \text{if `Male`}
\end{cases}}
\]</span></p>
<!-- <span style="color:red;">$x_{1} = \begin{cases} 1& \text{if ``Female''} \\ 0& \text{if ``Male''}\end{cases}$</span> -->
<p>This can also be written as <span class="math inline">\(I(x_{i1} = \text{`Female`})\)</span>, where <span class="math inline">\(I()\)</span> is an indicator variable, taking the value 1 if the condition in parentheses is true, and zero otherwise. An indicator always takes the values 0 or 1, to indicate the absence or presence of a particular characteristic (here the characteristic is ‘female’).</p>
<p>If all the regressor variables are indicator variables, then we are actually dealing with anova models (as we will see in Chapter 5); if some of the regressor variables are indicator variables, then we have analysis of covariance (ancova) models. Our first example of using indicator variables will be to fit two simple linear regression equations simultaneously. Consider the model:</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \epsilon_i
\]</span></p>
<p>for <span class="math inline">\(i = 1, \ldots, n\)</span>, where <span class="math inline">\(x_{i1}\)</span> is an indicator variable and <span class="math inline">\(x_{i2}\)</span> is a continuous variable. Then</p>
<ol style="list-style-type: decimal">
<li><span style="color: red;"><span class="math inline">\(\mathrm{E}(Y_i \mid x_{i1} = 0) = \beta_0 + \beta_2 x_{i2}\)</span>, and </span></li>
<li><span style="color: red;"><span class="math inline">\(\mathrm{E}(Y_i \mid x_{i1} = 1) = (\beta_0 + \beta_1) + \beta_2 x_{i2}\)</span> </span></li>
</ol>
<p>for <span class="math inline">\(i = 1, \ldots, n\)</span>. So what we are really doing is fitting two regression lines with a common slope, i.e. two parallel lines. The lines are separated in the vertical plane by the value of <span class="math inline">\(\beta_1\)</span>. Hence, if this value is close to zero then one line will suffice. Formally, we can test for a common intercept by testing</p>
<p><span class="math display">\[
\color{red}{H_0: \beta_1 = 0 \;\;\text{versus}\;\; H_1: \beta_1 \neq 0}
\]</span></p>
<p>in the usual way (i.e. we are testing for a common line, which corresponds to no difference between the two categories). To fit two lines with different slopes, we fit:</p>
<p><span class="math display">\[
\color{red}{Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \beta_3 x_{i1} x_{i2} + \epsilon_i, \;\; i = 1, \ldots, n}
\]</span></p>
<p>Under this formulation</p>
<ol style="list-style-type: decimal">
<li><span style="color: red;"><span class="math inline">\(\mathrm{E}(Y_i \mid x_{i1} = 0) = \beta_0 + \beta_2 x_{i2}\)</span> </span></li>
<li><span style="color: red;"><span class="math inline">\(\mathrm{E}(Y_i \mid x_{i1} = 1) = (\beta_0 + \beta_1) + (\beta_2 + \beta_3) x_{i2}\)</span> </span></li>
</ol>
<p>for <span class="math inline">\(i = 1, \ldots, n\)</span>. This is an interaction model! We can test for a common slope via
<span class="math display">\[
\color{red}{H_0: \beta_3 = 0 \;\;\text{versus}\;\; H_1: \beta_3 \neq 0.}
\]</span></p>
</div>
<div id="example-gasoline-data" class="section level2 unnumbered hasAnchor">
<h2>Example: Gasoline data<a href="categorical-variables-and-interactions.html#example-gasoline-data" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The data in the file <em>gasoline.RData</em> gives the gasoline mileage (<span class="math inline">\(y\)</span>), the engine displacement (<span class="math inline">\(x_1\)</span>) and the type of transmission (<span class="math inline">\(x_2\)</span>) for a sample of cars, where <span class="math inline">\(x_2\)</span> is coded as 0 for automatic transmission and 1 for manual transmission.</p>
<p>We begin by plotting the data. We can use the command <code>xyplot()</code> to produce an appropriate plot (although <code>plot()</code> can also be used with different symbols for each factor level).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:gasolinexyplot"></span>
<img src="general_linear_models_files/figure-html/gasolinexyplot-1.png" alt="Plot of mileage against engine displacement by transmission type." width="65%" />
<p class="caption">
Figure 4.1: Plot of mileage against engine displacement by transmission type.
</p>
</div>
<p>There is a clear difference in the intercepts with most automatic transmission points above manual transmission points. Mileage declines with engine displacement, and it looks like the rate of decline may be different for the two transmission types. In particular, there looks to be a steeper decline for cars with automatic transmission. Let us see what happens if we fit a common line, i.e. ignore transmission type.</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="categorical-variables-and-interactions.html#cb79-1" tabindex="-1"></a>m1 <span class="ot">=</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1, <span class="at">data =</span> gasoline)</span>
<span id="cb79-2"><a href="categorical-variables-and-interactions.html#cb79-2" tabindex="-1"></a><span class="fu">summary</span>(m1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1, data = gasoline)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.9498 -1.8377 -0.0842  1.8158  6.6023 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 34.026933   1.674994  20.315 2.40e-14 ***
## x1          -0.048408   0.006168  -7.848 2.22e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.324 on 19 degrees of freedom
## Multiple R-squared:  0.7643, Adjusted R-squared:  0.7519 
## F-statistic:  61.6 on 1 and 19 DF,  p-value: 2.224e-07</code></pre>
<p>Comments: <br>
<span style="color: red;">- We can see that engine displacement gives a very small <span class="math inline">\(p\)</span>-value , suggesting that this is very important. <br>
- However, we have ignored the crucial information on transmission type, and this can give misleading conclusions. </span></p>
<p>We can add the fitted line to the raw data using <code>abline(m1)</code>:</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:gasolinefitplot"></span>
<img src="general_linear_models_files/figure-html/gasolinefitplot-1.png" alt="Plot of mileage against engine displacement by transmission type with line of best fit overlaid." width="65%" />
<p class="caption">
Figure 4.2: Plot of mileage against engine displacement by transmission type with line of best fit overlaid.
</p>
</div>
<p>We can see that the line captures that there is a decline with engine displacement. However, it does not fit the data well, particularly for automatic transmission cars, because we have ignored transmission type. We will now add in the transmission type, allowing a test of</p>
<p><span class="math display">\[
\color{red}{H_0: \beta_2 = 0 \;\;\text{versus}\;\; H_1: \beta_2 \neq 0}
\]</span></p>
<p>We use the <code>R</code> commands</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="categorical-variables-and-interactions.html#cb81-1" tabindex="-1"></a>m2 <span class="ot">=</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2, <span class="at">data =</span> gasoline)</span>
<span id="cb81-2"><a href="categorical-variables-and-interactions.html#cb81-2" tabindex="-1"></a><span class="fu">summary</span>(m2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1 + x2, data = gasoline)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -6.880 -1.970 -0.104  1.796  6.605 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 34.12798    1.89989  17.963  6.1e-13 ***
## x1          -0.04963    0.01162  -4.271  0.00046 ***
## x21          0.34592    2.76144   0.125  0.90170    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.414 on 18 degrees of freedom
## Multiple R-squared:  0.7645, Adjusted R-squared:  0.7383 
## F-statistic: 29.21 on 2 and 18 DF,  p-value: 2.231e-06</code></pre>
<p>We observe that the addition of the transmission type indicator variable is not significant, and <span class="math inline">\(R^2\)</span> has not changed much either. Perhaps a common slope is a plausible claim?</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:gasolinefitplot2"></span>
<img src="general_linear_models_files/figure-html/gasolinefitplot2-1.png" alt="Plot of mileage against engine displacement by transmission type with lines of best fit for each transmission type overlaid (automatic - black, manual - red)." width="65%" />
<p class="caption">
Figure 4.3: Plot of mileage against engine displacement by transmission type with lines of best fit for each transmission type overlaid (automatic - black, manual - red).
</p>
</div>
<p>Are we overlooking something? What about the gradients? We now fit a model with different intercepts <em>and</em> different slopes</p>
<p><span class="math display">\[
\color{red}{H_0: \beta_3 = 0 \;\;\text{versus}\;\; H_1: \beta_3 \neq 0}
\]</span></p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="categorical-variables-and-interactions.html#cb83-1" tabindex="-1"></a>m3 <span class="ot">=</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x1<span class="sc">:</span>x2, <span class="at">data =</span> gasoline)</span>
<span id="cb83-2"><a href="categorical-variables-and-interactions.html#cb83-2" tabindex="-1"></a><span class="fu">summary</span>(m3)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1 + x2 + x1:x2, data = gasoline)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.2712 -1.2042  0.2958  1.4758  3.5412 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  42.91963    2.78705  15.400 2.04e-11 ***
## x1           -0.11677    0.02022  -5.776 2.24e-05 ***
## x21         -13.77463    4.36449  -3.156  0.00577 ** 
## x1:x21        0.08329    0.02252   3.699  0.00178 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.615 on 17 degrees of freedom
## Multiple R-squared:  0.8695, Adjusted R-squared:  0.8465 
## F-statistic: 37.75 on 3 and 17 DF,  p-value: 9.809e-08</code></pre>
<p>We see that the <span class="math inline">\(p\)</span>-value for the interaction is significant beyond the <span class="math inline">\(1\%\)</span> level, suggesting the slopes are different and <span class="math inline">\(\beta_3 \neq 0\)</span>. Furthermore, we also see that the main effect of the transmission type is also now significant (also at the <span class="math inline">\(1\%\)</span> level). The conclusion for engine displacement is largely as before, with a significant (and negative) coefficient although the magnitude has now changed. <span class="math inline">\(R^2\)</span> has increased to around <span class="math inline">\(87\%\)</span>, indicating that this model captures more of the uncertainty in mileage.</p>
<p>These results highlight the need to always include all lower order terms up-to-and-including the highest order term. Adding the respective lines of best fit to the raw data now gives:</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:gasolinefitplot3"></span>
<img src="general_linear_models_files/figure-html/gasolinefitplot3-1.png" alt="Plot of mileage against engine displacement by transmission type with lines of best fit for each transmission type overlaid (automatic - black, manual - red) from interaction model." width="65%" />
<p class="caption">
Figure 4.4: Plot of mileage against engine displacement by transmission type with lines of best fit for each transmission type overlaid (automatic - black, manual - red) from interaction model.
</p>
</div>
<p>This is clearly a much better fit. Note the crossing lines, which are indicative of an interaction. Now that we are happier with our model we should carry out the usual residual checks (not included here).</p>
<div id="model-interpretation" class="section level3 unnumbered hasAnchor">
<h3>Model interpretation<a href="categorical-variables-and-interactions.html#model-interpretation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The final model is:</p>
<p><span class="math display">\[\begin{align*}
\color{red}{\text{Mileage} = 42.92} &amp;\color{red}{- 0.12\times\text{Engine displacement}} \\
&amp;\color{red}{- 13.77 \times I(\text{Transmission type} = 1)} \\
&amp;\color{red}{+ 0.08\times \text{Engine displacement} \times I(\text{Transmission type} = 1)}
\end{align*}\]</span></p>
<p>This can be expressed as two separate models:</p>
<p><span class="math display">\[\begin{align*}
\color{red}{\text{Type 0: Mileage}} &amp;\color{red}{= 42.92 - 0.12\times \text{Engine displacement}} \\
\color{red}{\text{Type 1: Mileage}} &amp;\color{red}{= 29.15 - 0.04\times \text{Engine displacement}}
\end{align*}\]</span></p>
<p>Overall it can be seen that the mileage decreases by 0.12 for every unit increase in engine displacement when the transmission is automatic, and by 0.04 units when the transmission is manual. The decrease is greater when the transmission is automatic, as we would expect based on our initial plot. The effect of engine displacement differs according to the transmission type and two non-parallel lines must be used to model the data.</p>
</div>
</div>
<div id="model-selection-criteria" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Model selection criteria<a href="categorical-variables-and-interactions.html#model-selection-criteria" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Recall <span class="math inline">\(R^2 = \text{RSS}/\text{TSS}\)</span>, is the coefficient of determination, i.e. the proportion of the total (corrected) sum of squares of the response <span class="math inline">\(Y\)</span> explained by the model. The aim is to select a model that accounts for as much of this variation as is practical, i.e. we would like to only include regressors that are useful in some sense.</p>
<p>However, <span class="math inline">\(R^2\)</span> cannot decrease as regressor variables are added to the model. Thus the maximum <span class="math inline">\(R^2\)</span> will always be the model that contains all the regressor variables. As more regressors are added <span class="math inline">\(R^2\)</span> increases, but ‘tails off’. Thus, we could choose <span class="math inline">\(k\)</span> (the number of regressors to include) at the ‘elbow’. In addition, some alternative measures exist which can be minimised or maximised directly, removing some of the subjective issues based around using <span class="math inline">\(R^2\)</span> alone.</p>
<div id="model-selection-criteria-adjusted-r2" class="section level3 hasAnchor" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> Model selection criteria: adjusted <span class="math inline">\(R^2\)</span><a href="categorical-variables-and-interactions.html#model-selection-criteria-adjusted-r2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The adjusted coefficient of determination is defined as</p>
<p><span class="math display">\[
\color{red}{R^2_{\text{adj}} = 1 - \frac{\text{RMS}}{\text{TMS}}}
\]</span></p>
<p>where <span class="math inline">\(\text{RMS}\)</span> is the residual mean square error and <span class="math inline">\(\text{TMS}\)</span> is the total mean square error. This approach rescales <span class="math inline">\(R^2\)</span> using the degrees of freedom. Assuming we have <span class="math inline">\(k\)</span> degrees of freedom</p>
<p><span class="math display">\[\begin{align*}
\color{red}{R^2_{\text{adj}}} &amp;\color{red}{= 1 - \frac{\text{RSS}/(n - p -1)}{\text{TSS}/(n - 1)}} \\
\\
&amp;\color{red}{= 1 - \frac{\text{(TSS - Reg SS)}/(n - p - 1)}{\text{TSS}/(n - 1)}} \\
\\
&amp;\color{red}{= 1 - (1 - R^2)\frac{n - 1}{n - p - 1}}
\end{align*}\]</span></p>
<p>This equivalence can also be stated as</p>
<p><span class="math display">\[
\color{red}{\frac{(n - 1)R^2 - p}{n - p - 1}}
\]</span></p>
<p>Hence, to summarise</p>
<ul>
<li><span class="math inline">\(R^2\)</span> and <span class="math inline">\(R^2_{\text{adj}}\)</span> are directly related.</li>
<li>Adjusted <span class="math inline">\(R^2\)</span> need not always increase as variables are added to the model.</li>
<li>Adjusted <span class="math inline">\(R^2\)</span> tends to stabilise around some upper limit as variables are added.</li>
<li>The simplest model with an adjusted <span class="math inline">\(R^2\)</span> near this upper limit can be chosen as the ‘best’ model.</li>
</ul>
</div>
<div id="model-selection-criteria-akaikes-information-criterion" class="section level3 hasAnchor" number="4.2.2">
<h3><span class="header-section-number">4.2.2</span> Model selection criteria: Akaike’s Information Criterion<a href="categorical-variables-and-interactions.html#model-selection-criteria-akaikes-information-criterion" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In 1974, Hirotogu Akaike developed a criterion for model selection that has since come to bear his name, Akaike’s Information Criterion, which is typically abbreviated as AIC. The criterion offers a compromise between model complexity and goodness-of-fit and is defined as</p>
<p><span class="math display">\[\begin{align*}
\color{red}{\text{AIC}} &amp;\color{red}{= 2(p + 2)  - 2\ln L\left(\underline{\hat{\theta}}\right)} \\
&amp;\color{red}{= 2(p + 2) + n\ln(\text{RMS}) + c}
\end{align*}\]</span></p>
<p>where <span class="math inline">\(p\)</span> is the number of regressors in the model (hence <span class="math inline">\(p+2\)</span> is the total number of estimated parameters, including the residual variance), <span class="math inline">\(L\left(\underline{\hat{\theta}}\right)\)</span> is the likelihood for the model, <span class="math inline">\(\underline{\hat{\theta}}\)</span> is the vector of estimated parameters <em>including</em> the estimated residual variance. Also, <span class="math inline">\(\text{RMS} = (1 - R^2_{p, \text{adj}}) \text{TMS}\)</span> and, hence, AIC is also a function of adjusted <span class="math inline">\(R^2\)</span>. The larger adjusted <span class="math inline">\(R^2\)</span> is then <span class="math inline">\(n \ln (1 - R_{p, \text{adj}}^2)\)</span>, which is negative, becomes larger in absolute value. Therefore, AIC will also tend to choose a model with small <span class="math inline">\(p\)</span>, and with adjusted <span class="math inline">\(R^2\)</span> close to its maximum.</p>
</div>
</div>
<div id="reducing-the-number-of-variables" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> Reducing the number of variables<a href="categorical-variables-and-interactions.html#reducing-the-number-of-variables" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Often a regression model will include irrelevant explanatory variables, or will omit important explanatory variables. We try to include enough explanatory variables to explain the variation in the response variable adequately, however we would like to keep the number of explanatory variables down, since the variance of the prediction, <span class="math inline">\(\hat{Y}\)</span>, increases as the number of regressors increases. From a set of potential explanatory variables, the choice of which subset to choose is therefore a compromise between the two aims.</p>
<div id="backward-elimination" class="section level3 hasAnchor" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> Backward elimination<a href="categorical-variables-and-interactions.html#backward-elimination" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One unsophisticated method is to do the regression using all possible combinations of the explanatory variables and to just choose all the significant ones. This doesn’t work, because the explanatory variables all affect each other’s significance levels! It also requires the fitting of <span class="math inline">\(2^p - 1\)</span> models, which may be unfeasible for moderate <span class="math inline">\(p\)</span>.</p>
<p>Instead, we shall initially consider the method of removing the variable with the largest <span class="math inline">\(p\)</span>-value and continuing removing variables one at a time until all the remaining variables have small p-values (<span class="math inline">\(&lt; 0.05\)</span>), say, or there is no reduction in AIC. This is called <em>backward elimination</em>.</p>
</div>
<div id="forward-selection" class="section level3 hasAnchor" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> Forward selection<a href="categorical-variables-and-interactions.html#forward-selection" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>An alternative procedure is <em>forward selection</em> - this adds variables until the next candidate variable has a p-value &gt; 0.05, say, or does not decrease the value of AIC. It does not necessarily lead to the same model as backward elimination, depending on the correlation structure of the variables. Backward elimination is generally considered a safer strategy.</p>
</div>
<div id="stepwise-selection" class="section level3 hasAnchor" number="4.3.3">
<h3><span class="header-section-number">4.3.3</span> Stepwise selection<a href="categorical-variables-and-interactions.html#stepwise-selection" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We may be concerned that one-directional approaches, such as backwards elmination and forwards selection, lack flexibility as they make unanimous decisions about variables. Allowing a variable that has been removed at one step to subsequently return seems like a sensible approach - this is the idea behind <em>stepwise selection</em>. At each step this method looks at removing <em>or</em> adding variables, subject to some criterion, whereby variables can both enter and leave the model repeatedly; this is not the case with both backward elimination and forward selection. Starting with all the variables (i.e the full model), stepwise selection usually gives the same result as backward elimination; note that the model can also be initialised at the null model.</p>
<div id="automated-selection-using-aic" class="section level4 unnumbered hasAnchor">
<h4>Automated selection using AIC<a href="categorical-variables-and-interactions.html#automated-selection-using-aic" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>There is an automated procedure in <code>R</code> which performs each of the automated model selection methods, using Akaike’s Information criterion (AIC) as a stopping rule, which is useful when the number of potential regressors grows large. The procedure adds or removes variables until the minimum AIC is obtained. We can carry out the automated versions for each of backwards elimination, forward selection and stepwise selection using AIC in <code>R</code> using the <code>step()</code> command, with appropriate arguments.</p>
<!-- ### Example: Nurse performance data - forward selection {-} -->
<!-- ```{r nurseforward} -->
<!-- fitnull = lm(JobPerf ~ 1, data = NursePerform) -->
<!-- fitfs = step(fitnull, scope ~ Assert + Enthusiasm -->
<!--                 + Ambition + Communication + Problem -->
<!--                 + Initiative, direction = "forward") -->
<!-- ``` -->
<!-- So, `Ambition` is added at the first step since it has the lowest AIC amongst all simple linear regression models. -->
<!-- `Initiative` is added at the second step since it has the lowest AIC amongst all models, which must also include `Ambition` from step 1. `Enthusiasm` is added at the third step in a similar fashion. `Assert` is added at the fourth, and final, step  since neither of the remaining variables will further decrease the AIC. -->
<!-- Automated selection using AIC -->
<!-- There is an automated procedure in \texttt{R} which performs backward elimination using Akaike’s Information criterion (AIC), which is useful when the number of potential regressors grows large. The procedure removes variables until the minimum AIC is obtained. We can carry out the automated versions for each of backwards elimination, forward selection and stepwise selection using AIC in \texttt{R} using the \texttt{step()} command.  -->
<!-- ### Example: Nurse performance data - stepwise selection {-} -->
<!-- We can apply the stepwise procedure using the same `R` command `step()`, needing only to change the `direction` argument. Note that for this method we can either start with the null or full model due to its iterative nature. -->
<!-- ```{r nursestep} -->
<!-- fitstep <- step(fitall, direction="both") -->
<!-- ``` -->
<!-- As expected, the first step removes `Problem` - the same as backward elimination. We now see that this method considers bringing back in discarded variables at each iteration - although this is not warranted in this example. We obtain the same model for all three methods in this case. Note that this is not always the case, particularly for large, complex datasets with higher multicollinearity. -->
</div>
</div>
</div>
<div id="multicollinearity-and-the-variance-inflation-factor" class="section level2 hasAnchor" number="4.4">
<h2><span class="header-section-number">4.4</span> Multicollinearity and the variance inflation factor<a href="categorical-variables-and-interactions.html#multicollinearity-and-the-variance-inflation-factor" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We have mentioned earlier in the module about the problems that can occur if there is a high correlation between the explanatory variables:</p>
<ol style="list-style-type: lower-roman">
<li>Problems inverting <span class="math inline">\(\mathrm{X}^T\mathrm{X}\)</span>;</li>
<li>Conflicting results between the omnibus test and tests for individual covariates.</li>
</ol>
<p>Multicollinearity can also subtly lead to overestimation of standard errors and errors in relation to the importance of explanatory variables. When there are only two explanatory variables, we can calculate the correlation between them, but, as the number of explanatory variables increases, it can be difficult to see if there is a problem merely from the pairwise correlations. One approach is to calculate the <em>variance inflation factor</em> (VIF) for each explanatory variable.</p>
<div id="variance-inflation-factors" class="section level3 hasAnchor" number="4.4.1">
<h3><span class="header-section-number">4.4.1</span> Variance inflation factors<a href="categorical-variables-and-interactions.html#variance-inflation-factors" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider a case where there are <span class="math inline">\(p\)</span> possible explanatory variables. To calculate the VIF for the <span class="math inline">\(k^{th}\)</span> explanatory variable, we regress <span class="math inline">\(x_k\)</span> against the other explanatory variables, i.e. <span class="math inline">\(x_1, \ldots, x_{k-1}, x_{k + 1}, \ldots, x_p\)</span>. If <span class="math inline">\(R_k^2\)</span> is the coefficient of determination from this model then</p>
<p><span class="math display">\[
\color{red}{\text{VIF}_k = \frac{1}{1 - R_k^2}}
\]</span></p>
<p>As an ad hoc rule, we would consider removing a variable if <span class="math inline">\(\text{VIF}_k &gt; 5\)</span> and its associated <span class="math inline">\(p\)</span>-value is large. If <span class="math inline">\(\text{VIF}_k\)</span> is close to 1 that implies that <span class="math inline">\(x_k\)</span> is uncorrelated with the other explanatory variables. We can obtain the VIFs directly in <code>R</code> if we first (install and) load the library <code>car</code>.</p>
</div>
<div id="example-variance-inflation-factors" class="section level3 unnumbered hasAnchor">
<h3>Example: Variance inflation factors<a href="categorical-variables-and-interactions.html#example-variance-inflation-factors" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We now return to some previous examples and calculate the variance inflation factors.</p>
<ol type="i">
<li>
<p>Cheese data</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="categorical-variables-and-interactions.html#cb85-1" tabindex="-1"></a><span class="co"># Load the required library</span></span>
<span id="cb85-2"><a href="categorical-variables-and-interactions.html#cb85-2" tabindex="-1"></a><span class="fu">library</span>(car)</span></code></pre></div>
<pre><code>## Loading required package: carData</code></pre>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="categorical-variables-and-interactions.html#cb87-1" tabindex="-1"></a><span class="fu">load</span>(<span class="st">&quot;cheese2.RData&quot;</span>)</span>
<span id="cb87-2"><a href="categorical-variables-and-interactions.html#cb87-2" tabindex="-1"></a>fitcheese <span class="ot">=</span> <span class="fu">lm</span>(Taste <span class="sc">~</span> Acetic <span class="sc">+</span> H2S <span class="sc">+</span> Lactic <span class="sc">+</span> </span>
<span id="cb87-3"><a href="categorical-variables-and-interactions.html#cb87-3" tabindex="-1"></a>                 Phosphoric <span class="sc">+</span> Citric, <span class="at">data =</span> cheese2)</span>
<span id="cb87-4"><a href="categorical-variables-and-interactions.html#cb87-4" tabindex="-1"></a><span class="fu">vif</span>(fitcheese)</span></code></pre></div>
<pre><code>##     Acetic        H2S     Lactic Phosphoric     Citric 
##   2.231004   2.036519   1.974788   1.247715   1.060696</code></pre>
The variables are essentially uncorrelated for these data. Note that the method outlined above only works for regressors with a single degree of freedom. Generalised VIFs can be calculated when we have factors with <span class="math inline">\(&gt;2\)</span> levels.
</li>
<li>
<p>Warfarin dose data</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="categorical-variables-and-interactions.html#cb89-1" tabindex="-1"></a><span class="fu">load</span>(<span class="st">&quot;warfarinStudy.RData&quot;</span>)</span>
<span id="cb89-2"><a href="categorical-variables-and-interactions.html#cb89-2" tabindex="-1"></a>m2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(warfarin_dose <span class="sc">~</span> age <span class="sc">+</span> height, <span class="at">data =</span> warfarinStudy)</span>
<span id="cb89-3"><a href="categorical-variables-and-interactions.html#cb89-3" tabindex="-1"></a><span class="fu">vif</span>(m2)</span></code></pre></div>
<pre><code>##      age   height 
## 11.77452 11.77452</code></pre>
Strong evidence that one variable should be removed. Typically, we use <span class="math inline">\(t\)</span>-statistics or sequential anova to decide which to remove. Recall, we decided in Chapter 3 to remove height as it had a larger <span class="math inline">\(p\)</span>-value when fitted last. Note: when there are only two explanatory variables, the VIFs will always be the same. Why?
</li>
<!-- <li> Job performance of nurses data -->
<!-- ```{r vifnurse} -->
<!-- vif(fitall) -->
<!-- ``` -->
<!-- None of the VIFs are particularly high and so there is no reason, from a multicollinearity standpoint, to remove any of them.  -->
<!-- </li> -->
</ol>
</div>
</div>
<div id="transformations" class="section level2 hasAnchor" number="4.5">
<h2><span class="header-section-number">4.5</span> Transformations<a href="categorical-variables-and-interactions.html#transformations" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>There are three mian reasons for transforming variables in regression:</p>
<ol type="i">
<li>
<span style="color: red;">To cope with non-normality in the residuals. </span>
</li>
<li>
<span style="color: red;">To make the variance of the response variable, and hence the residuals, homogeneous.</span>
</li>
<li>
<span style="color: red;">To simplify the relationship between the response variable and the explanatory variables. </span>
</li>
</ol>
<p>If the residuals are asymmetric with a long tail upwards, or if the variance is increasing, then it may be worth trying a log transformation (see chapter 3) or a square root or cube root transformation of the response variable. We should then re-fit the model and re-examine the residuals to see if the problem is resolved; the <span class="math inline">\(R^2\)</span> value should increase if the model fits better.</p>
<div id="the-box-cox-transformation" class="section level3 hasAnchor" number="4.5.1">
<h3><span class="header-section-number">4.5.1</span> The Box-Cox transformation<a href="categorical-variables-and-interactions.html#the-box-cox-transformation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="overview" class="section level4 unnumbered hasAnchor">
<h4>Overview<a href="categorical-variables-and-interactions.html#overview" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Suppose that our relationship is not linear, but rather we have the model:</p>
<p><span class="math display">\[
\underline{Y}^{(\lambda)} = \mathrm{X}\underline{\beta} + \underline{\epsilon}
\]</span></p>
<p>where
<span class="math display">\[
  \underline{Y}^{(\lambda)}=
  \begin{cases}
              \frac{\underline{Y}^{\lambda} - 1}{\lambda} \hspace{0.5in}\textrm{if}\hspace{0.5in}\lambda \neq 0, \\
               \log{\underline{Y}} \hspace{0.5in}\textrm{if}\hspace{0.5in}\lambda = 0.
            \end{cases}
\]</span></p>
<p>We make the usual assumptions about the error terms and note that a choice of <span class="math inline">\(\lambda = 1\)</span> is equivalent to no transformation, and <span class="math inline">\(\lambda = 0\)</span> denotes the log-transformation. Given some data, and this model, we could estimate the parameters simultaneously to determine an estimated transformation. We note that we cannot use ordinary least squares because the model is now non-linear. Suppose, however, temporarily that we know <span class="math inline">\(\lambda\)</span>.</p>
<p>In this case, we could proceed as before to get:</p>
<p><span class="math display">\[\begin{align*}
\underline{\hat{\beta}} &amp;= \left(\mathrm{X}^T\mathrm{X}\right)^{-1} \mathrm{X}^T \underline{Y}^{(\lambda)} \\
\sigma_{\epsilon}^2 &amp;= \frac{1}{n - p - 1} \left(\underline{Y}^{(\lambda)}\right)^T (\mathrm{I} - \mathrm{H})\underline{Y}^{(\lambda)}
\end{align*}\]</span></p>
<p>If we plug these into the likelihood, it is now purely a function of <span class="math inline">\(\lambda\)</span>. We can then find the value of <span class="math inline">\(\lambda\)</span> that maximises the (profile) likelihood.</p>
</div>
</div>
<div id="example-box-cox-transformation" class="section level3 unnumbered hasAnchor">
<h3>Example: Box-Cox transformation<a href="categorical-variables-and-interactions.html#example-box-cox-transformation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In a study of the doubling time of yeast cells, several samples of yeast were observed over time and the average number of cells recorded, giving rise to the data below, which is entered into <code>R</code> (and plotted) as follows:</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="categorical-variables-and-interactions.html#cb91-1" tabindex="-1"></a>cells <span class="ot">=</span> <span class="fu">c</span>(<span class="fl">1.00</span>, <span class="fl">1.21</span>, <span class="fl">1.476641</span>, <span class="fl">1.838118</span>, <span class="fl">2.375750</span>, <span class="fl">2.560843</span>, <span class="fl">3.653237</span>, <span class="fl">4.592888</span>, <span class="fl">5.214563</span>, </span>
<span id="cb91-2"><a href="categorical-variables-and-interactions.html#cb91-2" tabindex="-1"></a>             <span class="fl">6.337479</span>, <span class="fl">6.201024</span>, <span class="fl">7.929808</span>,  <span class="fl">9.438030</span>, <span class="fl">14.838897</span>, <span class="fl">15.411255</span>, <span class="fl">23.615537</span>)</span>
<span id="cb91-3"><a href="categorical-variables-and-interactions.html#cb91-3" tabindex="-1"></a>time <span class="ot">=</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">3</span>, <span class="at">by =</span> <span class="fl">0.2</span>)</span>
<span id="cb91-4"><a href="categorical-variables-and-interactions.html#cb91-4" tabindex="-1"></a><span class="fu">plot</span>(time, cells, <span class="at">cex.lab =</span> <span class="fl">1.2</span>, <span class="at">pch =</span> <span class="dv">16</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:nonlinplot"></span>
<img src="general_linear_models_files/figure-html/nonlinplot-1.png" alt="Plot of yeast cells over time." width="65%" />
<p class="caption">
Figure 4.5: Plot of yeast cells over time.
</p>
</div>
<p>The plot is clearly non-linear with an upward curve (exponential growth?). There is also a suggestion of an increasing variance over time. Nevertheless, we will go ahead and fit the linear regression to demonstrate its failings in cases such as this.</p>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="categorical-variables-and-interactions.html#cb92-1" tabindex="-1"></a>m1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(cells <span class="sc">~</span> time)</span>
<span id="cb92-2"><a href="categorical-variables-and-interactions.html#cb92-2" tabindex="-1"></a><span class="fu">summary</span>(m1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = cells ~ time)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.4894 -2.1234 -0.7112  1.3418  8.0061 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   -2.148      1.435  -1.497    0.157    
## time           5.919      0.815   7.262 4.14e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.006 on 14 degrees of freedom
## Multiple R-squared:  0.7902, Adjusted R-squared:  0.7753 
## F-statistic: 52.74 on 1 and 14 DF,  p-value: 4.144e-06</code></pre>
<p>Comment: <span style="color: red;"> Despite the fact that the data is clearly not linear, the slope parameter is highly significant (<span class="math inline">\(p&lt;0.001\)</span>) and <span class="math inline">\(R^2\)</span> is quite large (<span class="math inline">\(79\%\)</span>). </span></p>
<p>However, if we plot the standardised residuals against the fitted values using the following <code>R</code> code we obtain:</p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="categorical-variables-and-interactions.html#cb94-1" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">fitted.values</span>(m1), <span class="fu">rstandard</span>(m1), </span>
<span id="cb94-2"><a href="categorical-variables-and-interactions.html#cb94-2" tabindex="-1"></a>       <span class="at">xlab=</span><span class="st">&quot;Fitted values&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;Standardised residuals&quot;</span>, </span>
<span id="cb94-3"><a href="categorical-variables-and-interactions.html#cb94-3" tabindex="-1"></a>       <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">cex.lab =</span> <span class="fl">1.2</span>)</span>
<span id="cb94-4"><a href="categorical-variables-and-interactions.html#cb94-4" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">2</span>), <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:nonlinres"></span>
<img src="general_linear_models_files/figure-html/nonlinres-1.png" alt="Standardised residuals against fitted values for the yeast cells model." width="65%" />
<p class="caption">
Figure 4.6: Standardised residuals against fitted values for the yeast cells model.
</p>
</div>
<p>The plot has clear curvature and a fairly extreme outlier, showing that the model is inappropriate. However, we can use the fitted model in order to see how the likelihood varies with values of <span class="math inline">\(\lambda\)</span>. This can be done in <code>R</code> via the <code>boxcox()</code> function (in conjunction with a fitted model object). Note that we need to load the <code>MASS</code> library to use the <code>boxcox()</code> function. We can produce the plot and extract the value of <span class="math inline">\(\lambda\)</span> that maximises the log-likelihood as follows:</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="categorical-variables-and-interactions.html#cb95-1" tabindex="-1"></a><span class="fu">library</span>(MASS) <span class="co"># Load the MASS library</span></span>
<span id="cb95-2"><a href="categorical-variables-and-interactions.html#cb95-2" tabindex="-1"></a>bc <span class="ot">=</span> <span class="fu">boxcox</span>(m1, <span class="at">lambda =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="fl">0.5</span> , <span class="fl">0.5</span>, <span class="at">by =</span> <span class="fl">0.01</span>), <span class="at">plotit =</span> T)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:boxcox"></span>
<img src="general_linear_models_files/figure-html/boxcox-1.png" alt="Values of the log-likelihood against lambda for the yeast cells model." width="65%" />
<p class="caption">
Figure 4.7: Values of the log-likelihood against lambda for the yeast cells model.
</p>
</div>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="categorical-variables-and-interactions.html#cb96-1" tabindex="-1"></a><span class="co"># Extract the maximum </span></span>
<span id="cb96-2"><a href="categorical-variables-and-interactions.html#cb96-2" tabindex="-1"></a>bc<span class="sc">$</span>x[<span class="fu">which.max</span>(bc<span class="sc">$</span>y)]</span></code></pre></div>
<pre><code>## [1] -0.05</code></pre>
<p>Comments:</p>
<ul>
<li><span style="color: red;">The above plots the log-likelihood for various values of <span class="math inline">\(\lambda\)</span>. </span></li>
<li><span style="color: red;">We can see that the maximum is at about <span class="math inline">\(\lambda = -0.05\)</span> (the central dashed line). </span></li>
<li><span style="color: red;">However <span class="math inline">\(\lambda = 0\)</span> is in the <span class="math inline">\(95\%\)</span> range (between the left- and right-dotted lines) suggesting that a log transformation may be appropriate. </span></li>
</ul>
<p>We can now try a log-transformed model, which we can summarise and perform model-checking in the usual way, i.e.</p>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="categorical-variables-and-interactions.html#cb98-1" tabindex="-1"></a><span class="co"># Model fitting</span></span>
<span id="cb98-2"><a href="categorical-variables-and-interactions.html#cb98-2" tabindex="-1"></a>m2 <span class="ot">=</span>  <span class="fu">lm</span>(<span class="fu">log</span>(cells) <span class="sc">~</span> time)</span>
<span id="cb98-3"><a href="categorical-variables-and-interactions.html#cb98-3" tabindex="-1"></a><span class="fu">summary</span>(m2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(cells) ~ time)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.17548 -0.06187 -0.00518  0.06664  0.16721 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.01120    0.04916   0.228    0.823    
## time         0.99450    0.02792  35.617 3.89e-15 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.103 on 14 degrees of freedom
## Multiple R-squared:  0.9891, Adjusted R-squared:  0.9883 
## F-statistic:  1269 on 1 and 14 DF,  p-value: 3.887e-15</code></pre>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="categorical-variables-and-interactions.html#cb100-1" tabindex="-1"></a><span class="co"># Model checking</span></span>
<span id="cb100-2"><a href="categorical-variables-and-interactions.html#cb100-2" tabindex="-1"></a><span class="fu">plot</span>(time, <span class="fu">log</span>(cells), <span class="at">pch =</span> <span class="dv">16</span>)</span>
<span id="cb100-3"><a href="categorical-variables-and-interactions.html#cb100-3" tabindex="-1"></a><span class="fu">abline</span>(m2, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>) <span class="co"># Add fitted line </span></span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:transres-1"></span>
<img src="general_linear_models_files/figure-html/transres-1.png" alt="Standardised residuals against fitted values for the transformed yeast cells model." width="65%" />
<p class="caption">
Figure 4.8: Standardised residuals against fitted values for the transformed yeast cells model.
</p>
</div>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="categorical-variables-and-interactions.html#cb101-1" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">fitted.values</span>(m2), <span class="fu">rstandard</span>(m2), <span class="at">xlab =</span> <span class="st">&quot;Fitted values&quot;</span>, </span>
<span id="cb101-2"><a href="categorical-variables-and-interactions.html#cb101-2" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;Standardised residuals&quot;</span>, <span class="at">pch =</span> <span class="dv">16</span>) </span>
<span id="cb101-3"><a href="categorical-variables-and-interactions.html#cb101-3" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">2</span>), <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:transres-2"></span>
<img src="general_linear_models_files/figure-html/transres-2.png" alt="Standardised residuals against fitted values for the transformed yeast cells model." width="65%" />
<p class="caption">
Figure 4.9: Standardised residuals against fitted values for the transformed yeast cells model.
</p>
</div>
<p>Comments:</p>
<ul>
<li>The <span class="math inline">\(R^2\)</span> value has substantially increased to <span class="math inline">\(98.9\%\)</span> (from <span class="math inline">\(79\%\)</span>), showing a much better model fit.</li>
<li>From the first plot the transformed data seem to fit well to a straight line.</li>
<li>From the second plot we can see that the curvature has gone, but there is still a slight suggestion of an increase in variance.</li>
<li>All points are within <span class="math inline">\((-2,2)\)</span> and so there are no outliers.</li>
</ul>
<p>Other standard model checking should also be done, e.g. a quantile-quantile plot to check the normality assumption, alongside an Anderson-Darling test.</p>
<div id="transforming-the-explanatory-variables" class="section level4 hasAnchor" number="4.5.1.1">
<h4><span class="header-section-number">4.5.1.1</span> Transforming the explanatory variable(s)<a href="categorical-variables-and-interactions.html#transforming-the-explanatory-variables" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The Box-Cox method only deals with transforming the response variable, although we can also model the explanatory variable as the response - as in multicollinearity - in a null model (see later). Sometimes it is necessary to transform the explanatory variables as well. If an explanatory variable has a very asymmetric distribution then the unusual values often become highly influential points. Transforming the variable to make the distribution more symmetric (e.g. taking logs or square roots) is usually desirable.</p>

</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="inference-for-the-multiple-linear-regression-model.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="analysis-of-designed-experiments.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/general_linear_models.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["notes.pdf", "notes.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
